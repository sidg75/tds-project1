{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOp0d8OI3sq1IqqrJk3TUqm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidg75/tds-project1/blob/main/TDSGitHubGraphQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import requests\n",
        "import time\n",
        "import os\n",
        "\n",
        "\n",
        "# GitHub GraphQL API URL\n",
        "GITHUB_GRAPHQL_URL = \"https://api.github.com/graphql\"\n",
        "\n",
        "# Your GitHub Personal Access Token (replace 'your_token' with your actual token)\n",
        "TOKEN = 'refer github profile>settings for token'\n",
        "\n",
        "\n",
        "# GraphQL headers with your personal access token\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"Bearer {TOKEN}\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "# GraphQL query to search for users in Sydney with more than 100 followers\n",
        "USER_SEARCH_QUERY = \"\"\"\n",
        "query($location: String!, $after: String) {\n",
        "  search(query: $location, type: USER, first: 50, after: $after) {\n",
        "    userCount\n",
        "    pageInfo {\n",
        "      endCursor\n",
        "      hasNextPage\n",
        "    }\n",
        "    edges {\n",
        "      node {\n",
        "        ... on User {\n",
        "          login\n",
        "          name\n",
        "          company\n",
        "          location\n",
        "          email\n",
        "          isHireable\n",
        "          bio\n",
        "          publicRepositories: repositories {\n",
        "            totalCount\n",
        "          }\n",
        "          followers {\n",
        "            totalCount\n",
        "          }\n",
        "          following {\n",
        "            totalCount\n",
        "          }\n",
        "          createdAt\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# GraphQL query to get up to 500 repositories for a given user\n",
        "USER_REPOS_QUERY = \"\"\"\n",
        "query($login: String!, $after: String) {\n",
        "  user(login: $login) {\n",
        "    repositories(first: 100, after: $after, ownerAffiliations: OWNER) {\n",
        "      pageInfo {\n",
        "        endCursor\n",
        "        hasNextPage\n",
        "      }\n",
        "      nodes {\n",
        "        name\n",
        "        createdAt\n",
        "        stargazerCount\n",
        "        watchers {\n",
        "          totalCount\n",
        "        }\n",
        "        primaryLanguage {\n",
        "          name\n",
        "        }\n",
        "        hasProjectsEnabled\n",
        "        hasWikiEnabled\n",
        "        licenseInfo {\n",
        "          key\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "def run_query(query, variables):\n",
        "    \"\"\"Run a GraphQL query with variables, with retry logic for rate limits.\"\"\"\n",
        "    while True:\n",
        "        response = requests.post(\n",
        "            GITHUB_GRAPHQL_URL,\n",
        "            json={\"query\": query, \"variables\": variables},\n",
        "            headers=HEADERS\n",
        "        )\n",
        "        if response.status_code == 200:\n",
        "            return response.json()\n",
        "        elif response.status_code == 403:  # Rate limit exceeded\n",
        "            remaining = response.headers.get(\"X-RateLimit-Remaining\", 0)\n",
        "            if remaining == \"0\":\n",
        "                reset_time = int(response.headers.get(\"X-RateLimit-Reset\", 0))\n",
        "                wait_time = max(0, reset_time - time.time())\n",
        "                print(f\"Rate limit exceeded. Waiting for {wait_time} seconds...\")\n",
        "                time.sleep(wait_time)\n",
        "            else:\n",
        "                time.sleep(5)  # Wait briefly if there's another error\n",
        "        else:\n",
        "            raise Exception(f\"Query failed with status code {response.status_code}: {response.text}\")\n",
        "\n",
        "\n",
        "def clean_company_name(company):\n",
        "    \"\"\"Clean and format company name: strip whitespace, remove '@', and convert to uppercase.\"\"\"\n",
        "    if company:\n",
        "        return company.strip().lstrip('@').upper()\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_users_in_sydney(min_followers=100):\n",
        "    \"\"\"Search for GitHub users in Sydney with more than min_followers.\"\"\"\n",
        "    users = []\n",
        "    after_cursor = None\n",
        "    search_query = f'location:\"Toronto\" followers:>{min_followers}'  # Updated search query\n",
        "\n",
        "    while True:\n",
        "        variables = {\"location\": search_query, \"after\": after_cursor}\n",
        "        result = run_query(USER_SEARCH_QUERY, variables)\n",
        "\n",
        "        if 'errors' in result:\n",
        "            print(f\"Error: {result['errors']}\")\n",
        "            break\n",
        "\n",
        "        if 'data' in result and 'search' in result['data'] and 'edges' in result['data']['search']:\n",
        "            users_data = result['data']['search']['edges']\n",
        "        else:\n",
        "            print(\"No users found or unexpected data structure.\")\n",
        "            break\n",
        "\n",
        "        for user in users_data:\n",
        "            user_node = user.get('node', {})\n",
        "            print(user_node)\n",
        "            # Ensure 'login' exists before accessing it\n",
        "            if 'login' not in user_node:\n",
        "                print(f\"Skipping user due to missing 'login' field: {user_node}\")\n",
        "                continue\n",
        "\n",
        "            #company = clean_company_name(user_node.get('company'))\n",
        "            company = user_node.get('company')\n",
        "            users.append({\n",
        "                \"login\": user_node.get('login'),\n",
        "                \"name\": user_node.get('name'),\n",
        "                \"company\": company,\n",
        "                \"location\": user_node.get('location'),\n",
        "                \"email\": user_node.get('email'),\n",
        "                \"hireable\": user_node.get('isHireable'),\n",
        "                \"bio\": user_node.get('bio'),\n",
        "                \"public_repos\": user_node['publicRepositories']['totalCount'],\n",
        "                \"followers\": user_node['followers']['totalCount'],\n",
        "                \"following\": user_node['following']['totalCount'],\n",
        "                \"created_at\": user_node['createdAt']\n",
        "            })\n",
        "\n",
        "        page_info = result['data']['search']['pageInfo']\n",
        "        if page_info['hasNextPage']:\n",
        "            after_cursor = page_info['endCursor']\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # Write users data to CSV\n",
        "    with open('users.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = ['login', 'name', 'company', 'location', 'email', 'hireable', 'bio', 'public_repos', 'followers', 'following', 'created_at']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        writer.writerows(users)\n",
        "    return users\n",
        "\n",
        "\n",
        "def get_repositories_for_user(login):\n",
        "    \"\"\"Retrieve up to 500 repositories for a given user.\"\"\"\n",
        "    repos = []\n",
        "    after_cursor = None\n",
        "    while len(repos) < 500:\n",
        "        variables = {\"login\": login, \"after\": after_cursor}\n",
        "        result = run_query(USER_REPOS_QUERY, variables)\n",
        "\n",
        "        # Debugging print to inspect the result structure\n",
        "        if 'data' not in result or 'user' not in result['data'] or not result['data']['user']:\n",
        "            print(f\"Skipping repositories for {login} due to missing data. Result: {result}\")\n",
        "            break\n",
        "\n",
        "        repos_data = result['data']['user']['repositories']['nodes']\n",
        "\n",
        "        for repo in repos_data:\n",
        "            repos.append({\n",
        "                \"login\": login,\n",
        "                \"full_name\": repo['name'],\n",
        "                \"created_at\": repo['createdAt'],\n",
        "                \"stargazers_count\": repo['stargazerCount'],\n",
        "                \"watchers_count\": repo['watchers']['totalCount'],\n",
        "                \"language\": repo['primaryLanguage']['name'] if repo['primaryLanguage'] else None,\n",
        "                \"has_projects\": repo['hasProjectsEnabled'],\n",
        "                \"has_wiki\": repo['hasWikiEnabled'],\n",
        "                \"license_name\": repo['licenseInfo']['key'] if repo['licenseInfo'] else None\n",
        "            })\n",
        "\n",
        "        page_info = result['data']['user']['repositories']['pageInfo']\n",
        "        if not page_info['hasNextPage'] or len(repos) >= 500:\n",
        "            break\n",
        "        after_cursor = page_info['endCursor']\n",
        "    return repos\n",
        "\n",
        "\n",
        "def main():\n",
        "    users = get_users_in_sydney(min_followers=100)\n",
        "    print(f\"Found {len(users)} users in Sydney with more than 100 followers.\\n\")\n",
        "\n",
        "    \"\"\"\n",
        "    # Open a single file to write all repositories\n",
        "    with open('repositories.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = ['login', 'full_name', 'created_at', 'stargazers_count', 'watchers_count', 'language', 'has_projects', 'has_wiki', 'license_name']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        for user in users:\n",
        "            print(f\"Getting repositories for {user['login']} (Followers: {user['followers']})...\")\n",
        "            repos = get_repositories_for_user(user['login'])\n",
        "\n",
        "            for repo in repos:\n",
        "                writer.writerow(repo)\n",
        "                print(f\"- {repo['full_name']} (Stars: {repo['stargazers_count']}, Watchers: {repo['watchers_count']})\")\n",
        "            print()\n",
        "    \"\"\"\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "Eb4CUmYfH56O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
